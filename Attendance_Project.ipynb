{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attendance Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSFwGSauXNgevmBSM42ZuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marioshady/Attendance-Marking-System/blob/main/Attendance_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OsPuM8aigwT",
        "outputId": "2b2190d0-92c8-4cac-90aa-bb91a484730f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0+zzzcolab20220513001918)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=197979652823d305132acedf095050b820887975197def35a525c762db611989\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlCVInIAiN4h",
        "outputId": "92a8d4f8-f04e-418f-d21a-d5a6bd56ff92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#run !pip install face_recognition then ed5ol 3al runtime w manage session w zawed hardware: GPU \n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import os\n",
        "from datetime import datetime\n",
        "from google.colab.patches import cv2_imshow \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/images'\n",
        "images = []\n",
        "classNames = []\n",
        "myList = os.listdir(path)\n",
        "print(myList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCeV1q4Biy_2",
        "outputId": "c4773c62-e256-4c14-fcc8-757869431cd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['elonmusk.jpg', 'dralaa.jpg', 'drashraf.jpg', 'mario.jpg', 'billgates.jpg', 'elonmusk2.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cl in myList:\n",
        "  #to initialize b zero law h-rerun el cell di \n",
        "  #classNames=[]\n",
        "  curImg = cv2.imread(f'{path}/{cl}')\n",
        "  images.append(curImg)\n",
        "  classNames.append(os.path.splitext(cl)[0])\n",
        "print(classNames)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrgCbXMxkfuf",
        "outputId": "32faef9c-5d5f-4628-d216-65b2296ebe1d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['elonmusk2', 'elonmusk', 'dralaa', 'drashraf', 'mario', 'billgates', 'elonmusk2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findEncodings(images):\n",
        "  encodeList = []\n",
        "  for img in images:\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    encode = face_recognition.face_encodings(img)[0]\n",
        "    encodeList.append(encode)\n",
        "  return encodeList"
      ],
      "metadata": {
        "id": "dyrwLQHbk5cI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodeListKnown = findEncodings(images)\n",
        "print('Encoding Complete')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjZn-yk6lz4u",
        "outputId": "0e9dd98b-db2d-4b4d-e11a-3b498e0b9c26"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def markAttendance(name):\n",
        "    with open('Attendance.csv','r+') as f:\n",
        "        myDataList = f.readlines()\n",
        "        nameList = []\n",
        "        for line in myDataList:\n",
        "            entry = line.split(',')\n",
        "            nameList.append(entry[0])\n",
        "        if name not in nameList:\n",
        "            now = datetime.now()\n",
        "            dtString = now.strftime('%H:%M:%S')\n",
        "            f.writelines(f'\\n{name},{dtString}')\n",
        " "
      ],
      "metadata": {
        "id": "XShLyJdkxOwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        " \n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    #img = captureScreen()\n",
        "    imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
        "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "    facesCurFrame = face_recognition.face_locations(imgS)\n",
        "    encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
        " \n",
        "    for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
        "        matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
        "        faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
        "        #print(faceDis)\n",
        "        matchIndex = np.argmin(faceDis)\n",
        " \n",
        "        if matches[matchIndex]:\n",
        "            name = classNames[matchIndex].upper()\n",
        "            #print(name)\n",
        "            y1,x2,y2,x1 = faceLoc\n",
        "            y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
        "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "            cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
        "            cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
        "            markAttendance(name)\n",
        " \n",
        "    cv2.imshow('Webcam',img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "_qE5OK-LmXWq",
        "outputId": "624e249e-e751-4596-f138-f512923a0003"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ba72066ccc0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}